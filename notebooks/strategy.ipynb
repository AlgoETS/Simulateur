{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install pycoingecko pandas numpy matplotlib noise scikit-learn tensorflow gym setuptools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install --upgrade pip tensorflow setuptools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pycoingecko import CoinGeckoAPI\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch data from CoinGecko\n",
    "cg = CoinGeckoAPI()\n",
    "bitcoin_data = cg.get_coin_market_chart_by_id(id='bitcoin', vs_currency='usd', days='365')\n",
    "prices = bitcoin_data['prices']\n",
    "df = pd.DataFrame(prices, columns=['timestamp', 'price'])\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
    "df.set_index('timestamp', inplace=True)\n",
    "\n",
    "# Preprocess Data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "df['price'] = scaler.fit_transform(df[['price']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create features and target\n",
    "window_size = 30\n",
    "features = []\n",
    "targets = []\n",
    "\n",
    "for i in range(len(df) - window_size):\n",
    "    features.append(df['price'].values[i:i + window_size])\n",
    "    targets.append(df['price'].values[i + window_size])\n",
    "\n",
    "features = np.array(features)\n",
    "targets = np.array(targets)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_size = int(len(features) * 0.8)\n",
    "train_features, test_features = features[:train_size], features[train_size:]\n",
    "train_targets, test_targets = targets[:train_size], targets[train_size:]\n",
    "\n",
    "# Define Actor and Critic Networks\n",
    "def create_actor(state_shape, action_shape):\n",
    "    state_input = layers.Input(shape=state_shape)\n",
    "    x = layers.Dense(64, activation=\"relu\")(state_input)\n",
    "    x = layers.Dense(64, activation=\"relu\")(x)\n",
    "    output = layers.Dense(action_shape[0], activation=\"tanh\")(x)\n",
    "    model = tf.keras.Model(state_input, output)\n",
    "    return model\n",
    "\n",
    "def create_critic(state_shape, action_shape):\n",
    "    state_input = layers.Input(shape=state_shape)\n",
    "    action_input = layers.Input(shape=action_shape)\n",
    "    concat = layers.Concatenate()([state_input, action_input])\n",
    "    x = layers.Dense(64, activation=\"relu\")(concat)\n",
    "    x = layers.Dense(64, activation=\"relu\")(x)\n",
    "    output = layers.Dense(1)(x)\n",
    "    model = tf.keras.Model([state_input, action_input], output)\n",
    "    return model\n",
    "\n",
    "state_shape = (window_size,)\n",
    "action_shape = (1,)\n",
    "actor = create_actor(state_shape, action_shape)\n",
    "critic = create_critic(state_shape, action_shape)\n",
    "\n",
    "# Implement the DDPG Algorithm\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, max_size=100000):\n",
    "        self.buffer = deque(maxlen=max_size)\n",
    "\n",
    "    def add(self, experience):\n",
    "        self.buffer.append(experience)\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        indices = np.random.choice(len(self.buffer), batch_size, replace=False)\n",
    "        batch = [self.buffer[idx] for idx in indices]\n",
    "        states, actions, rewards, next_states, dones = map(np.stack, zip(*batch))\n",
    "        return states, actions, rewards, next_states, dones\n",
    "\n",
    "class OUActionNoise:\n",
    "    def __init__(self, mean, std_deviation, theta=0.15, dt=1e-2, x_initial=None):\n",
    "        self.theta = theta\n",
    "        self.mean = mean\n",
    "        self.std_dev = std_deviation\n",
    "        self.dt = dt\n",
    "        self.x_initial = x_initial\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.x_prev = self.x_initial if self.x_initial is not None else np.zeros_like(self.mean)\n",
    "\n",
    "    def __call__(self):\n",
    "        x = self.x_prev + self.theta * (self.mean - self.x_prev) * self.dt + self.std_dev * np.sqrt(self.dt) * np.random.normal(size=self.mean.shape)\n",
    "        self.x_prev = x\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize noise and replay buffer\n",
    "noise = OUActionNoise(mean=np.zeros(1), std_deviation=0.2 * np.ones(1))\n",
    "replay_buffer = ReplayBuffer()\n",
    "\n",
    "# Training hyperparameters\n",
    "batch_size = 64\n",
    "gamma = 0.99\n",
    "tau = 0.005\n",
    "\n",
    "# Optimizers\n",
    "actor_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "critic_optimizer = tf.keras.optimizers.Adam(learning_rate=0.002)\n",
    "\n",
    "# Target networks\n",
    "target_actor = create_actor(state_shape, action_shape)\n",
    "target_critic = create_critic(state_shape, action_shape)\n",
    "target_actor.set_weights(actor.get_weights())\n",
    "target_critic.set_weights(critic.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_target(target_weights, weights, tau):\n",
    "    for (a, b) in zip(target_weights, weights):\n",
    "        a.assign(b * tau + a * (1 - tau))\n",
    "\n",
    "@tf.function\n",
    "def train_step(states, actions, rewards, next_states, dones):\n",
    "    rewards = tf.cast(rewards, tf.float32)\n",
    "    dones = tf.cast(dones, tf.float32)\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        target_actions = target_actor(next_states, training=True)\n",
    "        y = rewards + gamma * target_critic([next_states, target_actions], training=True) * (1 - dones)\n",
    "        critic_value = critic([states, actions], training=True)\n",
    "        critic_loss = tf.math.reduce_mean(tf.math.square(y - critic_value))\n",
    "\n",
    "    critic_grad = tape.gradient(critic_loss, critic.trainable_variables)\n",
    "    critic_optimizer.apply_gradients(zip(critic_grad, critic.trainable_variables))\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        actions = actor(states, training=True)\n",
    "        critic_value = critic([states, actions], training=True)\n",
    "        actor_loss = -tf.math.reduce_mean(critic_value)\n",
    "\n",
    "    actor_grad = tape.gradient(actor_loss, actor.trainable_variables)\n",
    "    actor_optimizer.apply_gradients(zip(actor_grad, actor.trainable_variables))\n",
    "\n",
    "    update_target(target_actor.variables, actor.variables, tau)\n",
    "    update_target(target_critic.variables, critic.variables, tau)\n",
    "\n",
    "# Define clear_output function\n",
    "def clear_output(wait=True):\n",
    "    from IPython.display import clear_output as clear\n",
    "    clear(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop with live plot update\n",
    "all_rewards = []\n",
    "\n",
    "for episode in range(1000):\n",
    "    state = train_features[0]\n",
    "    episode_reward = 0\n",
    "\n",
    "    for t in range(len(train_features) - 1):\n",
    "        state = train_features[t]\n",
    "        action = actor(tf.convert_to_tensor([state], dtype=tf.float32))[0] + noise()\n",
    "        action = tf.clip_by_value(action, -1.0, 1.0)\n",
    "        next_state = train_features[t + 1]\n",
    "        reward = train_targets[t]\n",
    "        done = t == len(train_features) - 2\n",
    "\n",
    "        replay_buffer.add((state, action, reward, next_state, done))\n",
    "\n",
    "        if len(replay_buffer.buffer) > batch_size:\n",
    "            states, actions, rewards, next_states, dones = replay_buffer.sample(batch_size)\n",
    "            train_step(states, actions, rewards, next_states, dones)\n",
    "\n",
    "        episode_reward += reward\n",
    "        state = next_state\n",
    "\n",
    "    all_rewards.append(episode_reward)\n",
    "    print(f\"Episode {episode}, Reward: {episode_reward}\")\n",
    "\n",
    "    # Plotting live update\n",
    "    if episode % 10 == 0:  # Update plot every 10 episodes\n",
    "        clear_output(wait=True)\n",
    "        plt.figure(figsize=(14, 7))\n",
    "        plt.plot(df.index[:train_size], df['price'][:train_size], label='Training Data')\n",
    "        plt.plot(df.index[train_size:], df['price'][train_size:], label='Test Data')\n",
    "        plt.plot(df.index[window_size:train_size], train_targets[:train_size - window_size], label='Actual Prices')\n",
    "        predicted_prices = [actor(tf.convert_to_tensor([train_features[i]], dtype=tf.float32))[0].numpy() for i in range(train_size - window_size)]\n",
    "        plt.plot(df.index[window_size:train_size], predicted_prices, label='Predicted Prices')\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Normalized Price')\n",
    "        plt.legend()\n",
    "        plt.title('Training and Test Data Split')\n",
    "        plt.show()\n",
    "\n",
    "    # Reset noise\n",
    "    noise.reset()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
